{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Roboflow class or paste the code in the cell below as obtained by using roboflow for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_object = 'your_path_to_your_object_detection_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"workspace_id\").project(\"project_id\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yoloversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Just update the paths for test, validation, and training from the downloaded dataset's data.yml file by replacing it with the whole path\\nsave it and then run the cells below\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Just update the paths for test, validation, and training from the downloaded dataset's data.yml file by replacing it with the whole path\n",
    "save it and then run the cells below'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8m.pt data={location}/data.yaml epochs=100  # train a YOLOv8 model for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75 ðŸš€ Python-3.11.9 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 218 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "                   all          6          6      0.993          1      0.995      0.995\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 0.0ms loss, 13.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Deep\\Desktop\\projects\\hackathon\\fryums-1\\valid\\labels.cache... 6 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Deep\\Desktop\\projects\\hackathon\\fryums-1\\valid\\labels.cache... 6 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.79s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=C:/Users/Deep/Desktop/projects/hackathon/runs/detect/train/weights/best.pt data={location}/data.yaml   # validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75 ðŸš€ Python-3.11.9 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 218 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\n",
      "image 1/3 C:\\Users\\Deep\\Desktop\\projects\\hackathon\\fryums-1\\test\\images\\frame_001452_jpg.rf.bce78974feaf5f9958857481ec4ee85f.jpg: 640x640 1 fryum, 15.8ms\n",
      "image 2/3 C:\\Users\\Deep\\Desktop\\projects\\hackathon\\fryums-1\\test\\images\\frame_001459_jpg.rf.a96d571cebfcd0588d16e62c78fd13dc.jpg: 640x640 1 fryum, 14.3ms\n",
      "image 3/3 C:\\Users\\Deep\\Desktop\\projects\\hackathon\\fryums-1\\test\\images\\frame_001827_jpg.rf.c8fccd808ab554572cf931066b47255d.jpg: 640x640 1 fryum, 15.9ms\n",
      "Speed: 2.7ms preprocess, 15.3ms inference, 66.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=C:/Users/Deep/Desktop/projects/hackathon/runs/detect/train/weights/best.pt conf = 0.25 source = C:/Users/Deep/Desktop/projects/hackathon/fryums-1/test/images  # predict on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the above cell, you will get the best model in the runs/detect folder in the train directory\n",
    "# You can use this model to predict on any image or video by changing the source path in the predict command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
